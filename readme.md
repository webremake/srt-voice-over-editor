# **SRT Voice-over Editor (Ollama + Gemma3)**

## **Назначение**
Этот скрипт предназначен для **редактирования субтитров в формате SRT для озвучки (voice-over)** с помощью локальной LLM, запущенной через **Ollama**.
Скрипт:

- редактирует **только текст внутри существующих строк**, делая его:
  - короче,
  - проще для устной речи,
  - пригодным для edtech-озвучки.

------

## **Архитектура решения**
Пайплайн выглядит так:

```
SRT
 ↓
JSON (строгая структура)
 ↓
LLM (редактирует только текст)
 ↓
JSON (валидация)
 ↓
SRT
```

Ключевая идея:

**модель физически лишена возможности менять таймкоды и структуру**, потому что работает только с текстовыми полями JSON.

------

## **Требования**

### **1. Операционная система**

- macOS (проверено)
- Linux (должно работать аналогично)

### **2. Установленный Ollama**

Проверка:

```bash
ollama --version
```

Проверка, что сервис запущен:

```bash
curl http://localhost:11434
```

Ожидаемый ответ:

```
Ollama is running
```

Если не запущен - запустить

```bash
ollama serve
```

### **3. Созданная модель**

В системе должна существовать кастомная модель:

```
gemma3-srt-voice-over-editor:4b
```

Проверка:

```
ollama list
```

Если модели нет — её нужно создать через ollama create с соответствующим Modelfile.

------

### **4. Python 3.10+**

Рекомендуется виртуальное окружение.

### **5. Python-зависимости**

```bash
pip install ollama pydantic srt
```

------
## **Структура файлов**

Пример минимальной структуры проекта:

```
project/
├── input.srt
├── output_voiceover.srt
├── script.py
└── README.md
```
------

## **Формат входного файла**

### **input.srt**

Обычный валидный SRT-файл:

```
1
00:00:00,300 --> 00:00:04,110
Итак, в этом видео я хочу рассмотреть
все крутые вещи, которые были добавлены
```

❗ Важно:

- структура SRT должна быть корректной,
- переносы строк внутри блока будут сохранены.

------

## **Что делает скрипт по шагам**

1. **Читает SRT**

2. Преобразует каждый блок в JSON:

   - index
   - start
   - end
   - lines[]

3. Валидирует структуру через pydantic

4. Отправляет JSON в локальную модель Ollama

5. Получает JSON с отредактированным текстом

6. Повторно валидирует JSON

7. Собирает финальный SRT

8. Сохраняет результат в файл

------

## **Гарантии безопасности**

Скрипт **гарантирует**, что модель:

- ❌ не изменит таймкоды,
- ❌ не объединит или не разобьёт блоки,
- ❌ не изменит количество строк,
- ❌ не добавит комментарии или пояснения,
- ❌ не начнёт переводить текст.


Если модель попытается это сделать — результат **не будет принят** и SRT не будет сохранён.

------


## **Запуск скрипта**

### **1. Убедитесь, что Ollama запущена**

```
curl http://localhost:11434
```

### **2. Запуск**

```
python script.py
```

По умолчанию:

- входной файл: input.srt
- выходной файл: output_voiceover.srt

------

## **Изменение имён файлов**

В конце скрипта:

```
if __name__ == "__main__":
    input_file = Path("input.srt")
    output_file = Path("output_voiceover.srt")
    process_srt(input_file, output_file)
```

Можно заменить на любые пути.

------

## **Для каких задач подходит**

✔ Edtech-видео
✔ Озвучка лекций
✔ Подкасты с таймкодами
✔ Voice-over без on-screen субтитров

------

## **Для каких задач НЕ подходит**
❌ Перевод
❌ Синхронизация таймингов
❌ Автоматическое объединение реплик
❌ Генерация новых субтитров

------

## **Возможные расширения (следующие шаги)**
- проверка скорости речи (символы / секунду),
- автоматические флаги риска для озвучки,
- сегментация длинных SRT по контекстному окну,
- QA-модель для проверки потери смысла.

------

## **Ключевая идея проекта**
> **LLM нельзя убедить соблюдать структуру.**
> **Её нужно лишить возможности её нарушить.**

Этот скрипт реализует именно это.